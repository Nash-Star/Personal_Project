{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediksi Data Saham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function LSTM\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def Sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def dSigmoid(values): \n",
    "    return values*(1-values)\n",
    "\n",
    "def dtanh(values): \n",
    "    return 1. - values**2\n",
    "\n",
    "# createst uniform random array w/ values in [a,b) and shape args\n",
    "def rand_arr(a, b, *args): \n",
    "    seed(0)\n",
    "    return rand(*args)*(b - a) + a\n",
    "\n",
    "class LstmParam:\n",
    "    def __init__(self, nc, x_dim):    \n",
    "        self.nc    = nc              #nc: number of cells, banyaknya cell di tiap time step\n",
    "        self.x_dim = x_dim           #x_dim jumlah features di X, atau time-steps \n",
    "        concat_len = x_dim + nc\n",
    "        \n",
    "        # weight matrices\n",
    "        self.wg = rand_arr(-0.1, 0.1, nc, concat_len)\n",
    "        self.wi = rand_arr(-0.1, 0.1, nc, concat_len) \n",
    "        self.wf = rand_arr(-0.1, 0.1, nc, concat_len)\n",
    "        self.wo = rand_arr(-0.1, 0.1, nc, concat_len)\n",
    "        \n",
    "        # bias terms\n",
    "        self.bg = rand_arr(-0.1, 0.1, nc) \n",
    "        self.bi = rand_arr(-0.1, 0.1, nc) \n",
    "        self.bf = rand_arr(-0.1, 0.1, nc) \n",
    "        self.bo = rand_arr(-0.1, 0.1, nc) \n",
    "        \n",
    "        # diffs (derivative of loss function w.r.t. all parameters)\n",
    "        self.wg_diff = zeros((nc, concat_len)) \n",
    "        self.wi_diff = zeros((nc, concat_len)) \n",
    "        self.wf_diff = zeros((nc, concat_len)) \n",
    "        self.wo_diff = zeros((nc, concat_len)) \n",
    "        self.bg_diff = zeros(nc) \n",
    "        self.bi_diff = zeros(nc) \n",
    "        self.bf_diff = zeros(nc) \n",
    "        self.bo_diff = zeros(nc) \n",
    "\n",
    "    def apply_diff(self, alpha = 1):\n",
    "        self.wg -= alpha*self.wg_diff\n",
    "        self.wi -= alpha*self.wi_diff\n",
    "        self.wf -= alpha*self.wf_diff\n",
    "        self.wo -= alpha*self.wo_diff\n",
    "        self.bg -= alpha*self.bg_diff\n",
    "        self.bi -= alpha*self.bi_diff\n",
    "        self.bf -= alpha*self.bf_diff\n",
    "        self.bo -= alpha*self.bo_diff\n",
    "        \n",
    "        # reset diffs to zero\n",
    "        self.wg_diff = zeros_like(self.wg)\n",
    "        self.wi_diff = zeros_like(self.wi) \n",
    "        self.wf_diff = zeros_like(self.wf) \n",
    "        self.wo_diff = zeros_like(self.wo) \n",
    "        self.bg_diff = zeros_like(self.bg)\n",
    "        self.bi_diff = zeros_like(self.bi) \n",
    "        self.bf_diff = zeros_like(self.bf) \n",
    "        self.bo_diff = zeros_like(self.bo) \n",
    "\n",
    "class LstmState:\n",
    "    def __init__(self, nc, x_dim):\n",
    "        self.g = zeros(nc)\n",
    "        self.i = zeros(nc)\n",
    "        self.f = zeros(nc)\n",
    "        self.o = zeros(nc)\n",
    "        self.s = zeros(nc)\n",
    "        self.h = zeros(nc)\n",
    "        self.bottom_diff_h = zeros_like(self.h)\n",
    "        self.bottom_diff_s = zeros_like(self.s)\n",
    "    \n",
    "class LstmNode:\n",
    "    def __init__(self, lstm_param, lstm_state):\n",
    "        # store reference to parameters and to activations\n",
    "        self.state = lstm_state\n",
    "        self.param = lstm_param\n",
    "        # non-recurrent input concatenated with recurrent input\n",
    "        self.xc = None\n",
    "\n",
    "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
    "        # if this is the first lstm node in the network\n",
    "        if s_prev is None: s_prev = zeros_like(self.state.s)\n",
    "        if h_prev is None: h_prev = zeros_like(self.state.h)\n",
    "            \n",
    "        # save data for use in backprop\n",
    "        self.s_prev = s_prev\n",
    "        self.h_prev = h_prev\n",
    "\n",
    "        # concatenate x(t) and h(t-1)\n",
    "        xc = np.hstack((x,  h_prev))\n",
    "        self.state.g = tanh(dot(self.param.wg, xc) + self.param.bg)\n",
    "        self.state.i = Sigmoid(dot(self.param.wi, xc) + self.param.bi)\n",
    "        self.state.f = Sigmoid(dot(self.param.wf, xc) + self.param.bf)\n",
    "        self.state.o = Sigmoid(dot(self.param.wo, xc) + self.param.bo)\n",
    "        self.state.s = self.state.g*self.state.i + s_prev*self.state.f\n",
    "        self.state.h = self.state.s*self.state.o\n",
    "\n",
    "        self.xc = xc\n",
    "    \n",
    "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
    "        # notice that top_diff_s is carried along the constant error carousel\n",
    "        ds = self.state.o*top_diff_h + top_diff_s\n",
    "        do = self.state.s*top_diff_h\n",
    "        di = self.state.g*ds\n",
    "        dg = self.state.i*ds\n",
    "        df = self.s_prev*ds\n",
    "\n",
    "        # diffs w.r.t. vector inside sigma / tanh function\n",
    "        di_input = dSigmoid(self.state.i)*di \n",
    "        df_input = dSigmoid(self.state.f)*df \n",
    "        do_input = dSigmoid(self.state.o)*do \n",
    "        dg_input = dtanh(self.state.g)*dg\n",
    "\n",
    "        # diffs w.r.t. inputs\n",
    "        self.param.wi_diff += outer(di_input, self.xc)\n",
    "        self.param.wf_diff += outer(df_input, self.xc)\n",
    "        self.param.wo_diff += outer(do_input, self.xc)\n",
    "        self.param.wg_diff += outer(dg_input, self.xc)\n",
    "        self.param.bi_diff += di_input\n",
    "        self.param.bf_diff += df_input       \n",
    "        self.param.bo_diff += do_input\n",
    "        self.param.bg_diff += dg_input       \n",
    "\n",
    "        # compute bottom diff\n",
    "        dxc  = zeros_like(self.xc)\n",
    "        dxc += dot(self.param.wi.T, di_input)\n",
    "        dxc += dot(self.param.wf.T, df_input)\n",
    "        dxc += dot(self.param.wo.T, do_input)\n",
    "        dxc += dot(self.param.wg.T, dg_input)\n",
    "\n",
    "        # save bottom diffs\n",
    "        self.state.bottom_diff_s = ds * self.state.f\n",
    "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
    "\n",
    "class LstmNetwork():\n",
    "    def __init__(self, lstm_param):\n",
    "        self.lstm_param = lstm_param\n",
    "        self.lstm_node_list = []\n",
    "        \n",
    "        # input sequence\n",
    "        self.x_list = []\n",
    "\n",
    "    def y_list_is(self, y_list, loss_layer):\n",
    "        \n",
    "        \"\"\"\n",
    "        Updates diffs by setting target sequence \n",
    "        with corresponding loss layer. \n",
    "        Will *NOT* update parameters.  To update parameters,\n",
    "        call self.lstm_param.apply_diff()\n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(y_list) == len(self.x_list)\n",
    "        idx = len(self.x_list) - 1\n",
    "        \n",
    "        # first node only gets diffs from label ...\n",
    "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "        \n",
    "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
    "        diff_s = zeros(self.lstm_param.nc)\n",
    "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "        idx -= 1\n",
    "\n",
    "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
    "        ### we also propagate error along constant error carousel using diff_s\n",
    "        while idx  >= 0:\n",
    "            loss   += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h  = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
    "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
    "            diff_s  = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
    "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
    "            idx    -= 1 \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def x_list_clear(self):\n",
    "        self.x_list = []\n",
    "\n",
    "    def x_list_add(self, x):\n",
    "        self.x_list.append(x)\n",
    "        \n",
    "        if len(self.x_list) > len(self.lstm_node_list):\n",
    "            # need to add new lstm node, create new state mem\n",
    "            lstm_state = LstmState(self.lstm_param.nc, self.lstm_param.x_dim)\n",
    "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
    "\n",
    "        # get index of most recent x input\n",
    "        idx = len(self.x_list) - 1\n",
    "        if idx == 0:\n",
    "            # no recurrent inputs yet\n",
    "            self.lstm_node_list[idx].bottom_data_is(x)\n",
    "        else:\n",
    "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
    "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
    "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n",
    "            \n",
    "class LossLayer:\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def loss(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] = 2 * (pred[0] - label)\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "#Parameters for input data dimension and lstm cell count\n",
    "    \n",
    "x       = pickle.load(open(\"HargaSaham.dat\", \"rb\"))   #Ini data harga saham sebanyak 250 observasi.\n",
    "xs      = (x-x.min())/(x.max()-x.min())   #Datanya distandardisasikan dulu\n",
    "N       = xs.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cek korelasi lag 1-10\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "#plot_acf(x, lags=10)\n",
    "plot_pacf(x, lags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         t-2       t-1         t\n",
      "0        NaN       NaN  0.562912\n",
      "1        NaN  0.562912  0.573332\n",
      "2   0.562912  0.573332  0.592352\n",
      "3   0.573332  0.592352  0.467694\n",
      "4   0.592352  0.467694  0.409983\n",
      "5   0.467694  0.409983  0.439758\n",
      "6   0.409983  0.439758  0.489736\n",
      "7   0.439758  0.489736  0.437683\n",
      "8   0.489736  0.437683  0.464447\n",
      "9   0.437683  0.464447  0.486067\n",
      "10  0.464447  0.486067  0.503275\n",
      "11  0.486067  0.503275  0.477026\n",
      "12  0.503275  0.477026  0.434892\n",
      "13  0.477026  0.434892  0.390080\n",
      "(250, 3)\n"
     ]
    }
   ],
   "source": [
    "# membuat Time Step / Time-Lag\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Xs = pd.DataFrame(xs)\n",
    "n = 3\n",
    "b = Xs\n",
    "\n",
    "for i in range(1,n):\n",
    "  a = Xs.shift(i)\n",
    "  b = pd.concat([a,b], axis=1)\n",
    "\n",
    "#dataset = pd.concat([b,Xs],axis=1)\n",
    "dataset = b\n",
    "dataset.columns = ['t-2','t-1','t']\n",
    "print(dataset.head(14))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "      <th>rm7</th>\n",
       "      <th>rm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562912</td>\n",
       "      <td>0.573332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.562912</td>\n",
       "      <td>0.573332</td>\n",
       "      <td>0.592352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.573332</td>\n",
       "      <td>0.592352</td>\n",
       "      <td>0.467694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.592352</td>\n",
       "      <td>0.467694</td>\n",
       "      <td>0.409983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.490010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.467694</td>\n",
       "      <td>0.409983</td>\n",
       "      <td>0.439758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.409983</td>\n",
       "      <td>0.439758</td>\n",
       "      <td>0.489736</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>0.446493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.439758</td>\n",
       "      <td>0.489736</td>\n",
       "      <td>0.437683</td>\n",
       "      <td>0.487220</td>\n",
       "      <td>0.455726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.489736</td>\n",
       "      <td>0.437683</td>\n",
       "      <td>0.464447</td>\n",
       "      <td>0.471665</td>\n",
       "      <td>0.463955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.437683</td>\n",
       "      <td>0.464447</td>\n",
       "      <td>0.486067</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>0.462732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t-2       t-1         t       rm7       rm3\n",
       "0       NaN       NaN  0.562912       NaN       NaN\n",
       "1       NaN  0.562912  0.573332       NaN       NaN\n",
       "2  0.562912  0.573332  0.592352       NaN  0.576199\n",
       "3  0.573332  0.592352  0.467694       NaN  0.544459\n",
       "4  0.592352  0.467694  0.409983       NaN  0.490010\n",
       "5  0.467694  0.409983  0.439758       NaN  0.439145\n",
       "6  0.409983  0.439758  0.489736  0.505110  0.446493\n",
       "7  0.439758  0.489736  0.437683  0.487220  0.455726\n",
       "8  0.489736  0.437683  0.464447  0.471665  0.463955\n",
       "9  0.437683  0.464447  0.486067  0.456481  0.462732"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new feature, rolling windows\n",
    "\n",
    "dataset['rm7'] = dataset['t'].rolling(window=7).mean()\n",
    "dataset['rm3'] = dataset['t'].rolling(window=3).mean()\n",
    "\n",
    "#data = data[['Datetime', 'rolling_mean', 'Count']]\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 5)\n",
      "         t-2       t-1         t       rm7       rm3\n",
      "6   0.409983  0.439758  0.489736  0.505110  0.446493\n",
      "7   0.439758  0.489736  0.437683  0.487220  0.455726\n",
      "8   0.489736  0.437683  0.464447  0.471665  0.463955\n",
      "9   0.437683  0.464447  0.486067  0.456481  0.462732\n",
      "10  0.464447  0.486067  0.503275  0.461564  0.484596\n"
     ]
    }
   ],
   "source": [
    "# Drop row with NaN data\n",
    "\n",
    "dataset.dropna(inplace=True)\n",
    "print(dataset.shape)\n",
    "print(dataset.head())\n",
    "#dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         t-2       t-1       rm7       rm3\n",
      "6   0.409983  0.439758  0.505110  0.446493\n",
      "7   0.439758  0.489736  0.487220  0.455726\n",
      "8   0.489736  0.437683  0.471665  0.463955\n",
      "9   0.437683  0.464447  0.456481  0.462732\n",
      "10  0.464447  0.486067  0.461564  0.484596\n",
      "6     0.489736\n",
      "7     0.437683\n",
      "8     0.464447\n",
      "9     0.486067\n",
      "10    0.503275\n",
      "Name: t, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into x and y\n",
    "\n",
    "datasetx = dataset.drop('t',1)\n",
    "datasety = dataset['t']\n",
    "\n",
    "print(datasetx.head())\n",
    "print(datasety.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into Array\n",
    "\n",
    "datasetx = np.array(datasetx)\n",
    "datasety = np.array(datasety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train =  (220, 4)\n",
      "y_train =  (220,)\n",
      "x_test =  (24, 4)\n",
      "y_test =  (24,)\n"
     ]
    }
   ],
   "source": [
    "# Split data jadi train dan test\n",
    "# dengan rolling mean()\n",
    "\n",
    "n_train = round(len(dataset)*0.9) # jumlah data train 90% dan test 10%\n",
    "\n",
    "x_train = datasetx[:n_train, :]\n",
    "y_train = datasety[:n_train]\n",
    "print(\"x_train = \", x_train.shape)\n",
    "print(\"y_train = \", y_train.shape)\n",
    "\n",
    "x_test = datasetx[n_train:, :]\n",
    "y_test = datasety[n_train:]\n",
    "print(\"x_test = \", x_test.shape)\n",
    "print(\"y_test = \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 60.1675\n",
      "loss: 0.0043\n",
      "\n",
      "Runtime: 0:08:45.595287\n"
     ]
    }
   ],
   "source": [
    "#Parameters for input data dimension and lstm cell count\n",
    "\n",
    "np.random.seed(2020)\n",
    "    \n",
    "N       = len(x_train)\n",
    "\n",
    "nc      = 7   #Number of cells, banyaknya cell per time step (boleh diubah-ubah sebagai hyerparameters)\n",
    "Ts      = 4   #Di literatur Time Series digunakan istilah 'time lag' sebagai padanan istilah 'timestep' ini\n",
    "alpha   = 0.005   #learning rate, Ts = 5 dan nc = 3 cukup bagus\n",
    "epochs  = 25001\n",
    "\n",
    "\n",
    "lstm_param = LstmParam(nc, Ts)\n",
    "lstm_net   = LstmNetwork(lstm_param)\n",
    "\n",
    "tic = datetime.now()\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(y_train)):   #Ts = len(y_list): time-steps\n",
    "        lstm_net.x_list_add(x_train[i])\n",
    "    \n",
    "    loss = lstm_net.y_list_is(y_train, LossLayer)\n",
    "    lstm_param.apply_diff(alpha)\n",
    "    lstm_net.x_list_clear()\n",
    "    \n",
    "    if epoch%((epochs-1)) == 0:\n",
    "        print(\"loss:\", \"%6.4f\" % loss)\n",
    "    #if epoch == 8001:\n",
    "        #print(\"loss last epoch:\", \"%6.4f\" % loss)\n",
    "\n",
    "toc = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Runtime:\", toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000019\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# MSE train set\n",
    "\n",
    "ytrain_pred = []\n",
    "\n",
    "for i in range(len(x_train)):   #Ts = len(y_list): time-steps\n",
    "        lstm_net.x_list_add(x_train[i])\n",
    "        ytrain_pred.append(lstm_net.lstm_node_list[i].state.h[0])\n",
    "\n",
    "lstm_net.x_list_clear()\n",
    "\n",
    "ytrain_pred = pd.DataFrame(ytrain_pred)\n",
    "ytrain_act = pd.DataFrame(y_train)\n",
    "\n",
    "# MSE\n",
    "loss = (ytrain_pred - ytrain_act)**2/len(ytrain_act)\n",
    "print(loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000046\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Predict test set\n",
    "\n",
    "ytest_pred = []\n",
    "\n",
    "for i in range(len(x_test)):   #Ts = len(y_list): time-steps\n",
    "        lstm_net.x_list_add(x_test[i])\n",
    "        ytest_pred.append(lstm_net.lstm_node_list[i].state.h[0])\n",
    "\n",
    "lstm_net.x_list_clear()\n",
    "\n",
    "ytest_pred = pd.DataFrame(ytest_pred)\n",
    "ytest_act = pd.DataFrame(y_test)\n",
    "\n",
    "# MSE\n",
    "loss = (ytest_pred - ytest_act)**2/len(ytest_act)\n",
    "print(loss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert back standardization to actual stock value\n",
    "\n",
    "## train ##\n",
    "ytrain_pred = []\n",
    "\n",
    "for i in range(len(x_train)):   #Ts = len(y_list): time-steps\n",
    "        lstm_net.x_list_add(x_train[i])\n",
    "        ytrain_pred.append(lstm_net.lstm_node_list[i].state.h[0])\n",
    "\n",
    "lstm_net.x_list_clear()\n",
    "\n",
    "ytrain = pd.DataFrame(ytrain_pred)\n",
    "\n",
    "#revert\n",
    "ytrain_pred = (ytrain * (x.max()-x.min())) + x.min()\n",
    "ytrain_act = (y_train * (x.max()-x.min())) + x.min()\n",
    "\n",
    "## test ##\n",
    "ytest_pred = []\n",
    "\n",
    "for i in range(len(x_test)):   #Ts = len(y_list): time-steps\n",
    "        lstm_net.x_list_add(x_test[i])\n",
    "        ytest_pred.append(lstm_net.lstm_node_list[i].state.h[0])\n",
    "\n",
    "lstm_net.x_list_clear()\n",
    "\n",
    "ytest = pd.DataFrame(ytest_pred)\n",
    "\n",
    "#revert\n",
    "ytest_pred = (ytest * (x.max()-x.min())) + x.min()\n",
    "ytest_act = (y_test * (x.max()-x.min())) + x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Data Train\n",
    "plt.plot(ytrain_act, label = 'actual')\n",
    "plt.plot(ytrain_pred,  label = 'predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot test\n",
    "\n",
    "plt.plot(ytest_act, label = 'actual')\n",
    "plt.plot(ytest_pred,  label = 'predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
