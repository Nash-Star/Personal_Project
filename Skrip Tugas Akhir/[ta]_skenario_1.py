# -*- coding: utf-8 -*-
"""[TA] Skenario 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C62X0dQSG1b2GfeFGUvEgEVYq0nsQJBk

## Skenario 1 
### Dengan Conv 8, hidden layer 32, lr 0.001
"""

# akses Google Drive
from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
##### CNN MODEL ####
# %tensorflow_version 1.x 
import warnings
import sys
import pandas as pd
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.optimizers import Adam
from keras import initializers
from keras.preprocessing.image import ImageDataGenerator


warnings.filterwarnings("ignore")

# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(8, (3, 3), activation='relu', kernel_initializer=initializers.he_uniform(seed=1), padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(16, activation='relu', kernel_initializer=initializers.he_uniform(seed=1)))
	model.add(Dense(3, activation='softmax'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	#opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.099, amsgrad=False)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
	return model

# Commented out IPython magic to ensure Python compatibility.
# plot diagnostic learning curves
def summarize_diagnostics(history):
# 	%matplotlib inline
	pyplot.figure(figsize=(8, 8), dpi=300)
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Model Cross Entropy Loss')
	pyplot.xlabel('Number of Epochs')
	pyplot.ylabel('Cross Entropy Loss')
	pyplot.ylim(0,2)
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	pyplot.legend()
	print("\n")
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Model Classification Accuracy')
	pyplot.xlabel('Number of Epochs')
	pyplot.ylabel('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	pyplot.legend()
	pyplot.tight_layout(pad=2.0)
	pyplot.show()
	#print(history.history.keys())
  #dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])
  # save plot to file
	#filename = sys.argv[0].split('/')[-1]
	#pyplot.savefig(filename + '_plot.png')
	#pyplot.close()

### COBA Confusion Matrix (bisa)

# run the test harness for evaluating a model
from sklearn.metrics import confusion_matrix
import numpy as np
import pandas as pd
import seaborn as sns
def run_test_harness():
  # define model
  model = define_model()
  # create data generator
  datagen = ImageDataGenerator(rescale=1.0/255.0)
  #datagen = ImageDataGenerator()
  # prepare iterators
  train_it = datagen.flow_from_directory('/content/gdrive/My Drive/Colab Notebooks/Dataset/RIPCurrent_keras/train/',
  	class_mode='categorical', batch_size=8, target_size=(200, 200))
  test_it = datagen.flow_from_directory('/content/gdrive/My Drive/Colab Notebooks/Dataset/RIPCurrent_keras/test/',
  	class_mode='categorical', batch_size=8, target_size=(200, 200))
  # fit model
  history = model.fit_generator(train_it, steps_per_epoch=len(train_it)/8,
  	validation_data=test_it, validation_steps=len(test_it)/8, epochs=50, verbose=2)
  # Save history training data
  loss = pd.DataFrame(history.history) 
  hist_csv_file = 'history.csv'
  with open(hist_csv_file, mode='w') as f:
    loss.to_csv(f)
  # evaluate model
  # predict test data
  #test_it.reset()
  Y_pred = model.predict_generator(test_it)
  classes = test_it.classes[test_it.index_array]
  y_pred = np.argmax(Y_pred, axis=-1)
  # using confusion matrix
  cm = confusion_matrix(test_it.classes[test_it.index_array],y_pred)
  confusmatrix = pd.DataFrame(cm)
  confusmatrix.columns = ['Rip 1','Rip 2','No Rip']
  confusmatrix.rename(index={0:'Rip 1', 1:'Rip 2', 2:'No Rip'}, inplace=True)  
  plot_cm = sns.heatmap(confusmatrix, annot=True, fmt="d")
  pyplot.xlabel("Predicted Label")
  pyplot.ylabel("True Label")
  pyplot.show()
  # calculate Accuracy
  _, acc = model.evaluate_generator(test_it, steps=2, verbose=0)
  print('Akurasi Model: %.5f' % (acc * 100.0))
  # learning curves
  summarize_diagnostics(history)
  # save model
  model.save('rip_model.h5')

# entry point, run the test harness
from datetime import datetime

toc = datetime.now()
run_test_harness()
tic = datetime.now()

print("Waktu running Model = {}".format(tic-toc))



### tebak gambar
# open image
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.models import load_model
import os
 
# load and prepare the image
def load_image(folder):
  images = []
  filenames = []
  for filename in os.listdir(folder):
    img = load_img(os.path.join(folder,filename), target_size=(200, 200))
    # convert to array
    img = img_to_array(img)
    # reshape into a single sample with 3 channels
    img = img.reshape(1, 200, 200, 3)
    img = img.astype('uint8')
    images.append(img)
    filenames.append(filename.replace(".jpg", " "))
  return images, filenames

coba,nama = load_image('/content/gdrive/My Drive/Colab Notebooks/Dataset/RIPCurrent_keras/coba/')

(coba[2].shape)
#len(coba)
#type(coba[1])
#print(coba[1])
#print(nama[1])

# load an image and predict the class
def run_example(img,name):
  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np

  # load model
  model = load_model('rip_model.h5')
  #print(model.summary())
  # predict the class
  result = model.predict(img)
  plt.figure()
  img = img.reshape(200, 200, 3)
  #img = imread(img)
  imgplot = plt.imshow(img)
  plt.title('Nama File asli : {}'.format(name))
  a = np.asarray(result)
  hasil_klasifikasi = pd.DataFrame(a)
  hasil_klasifikasi.columns = ['norip', 'rip 1', 'rip 2'] 
  print ('   Hasil prediksi model : ')
  print(hasil_klasifikasi)

run_example(coba[14],nama[14])

model = load_model('rip_model.h5')
print(model.summary())

hist_df = pd.DataFrame(history.history)

